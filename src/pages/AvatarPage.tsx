import { useState, useRef, useEffect } from "react";
import { VRMViewer, VRMViewerRef } from "~/components/VRMViewer";
import {
  Dock,
  DockIcon,
  DockItem,
  DockLabel,
} from "~/components/ui/shadcn-io/dock";
import {
  Mic,
  Settings as SettingsIcon,
  Home,
  Upload,
  ChevronDown,
} from "lucide-react";
import { predefinedAvatars, predefinedAnimations } from "~/constants";
import { Button } from "~/components/ui/button";
import { Switch } from "~/components/ui/switch";
import {
  DropdownMenu,
  DropdownMenuContent,
  DropdownMenuTrigger,
  DropdownMenuRadioItem,
} from "~/components/ui/dropdown-menu";
import {
  Dialog,
  DialogContent,
  DialogHeader,
  DialogTitle,
} from "~/components/ui/dialog";
import { useNavigate } from "react-router-dom";
import ollama from "ollama";

const AvatarPage = () => {
  const navigate = useNavigate();
  const [isRecording, setIsRecording] = useState(false);
  const [audioInputs, setAudioInputs] = useState<MediaDeviceInfo[]>([]);
  const [selectedInputId, setSelectedInputId] = useState<string>("");
  const [isVRMLoaded, setIsVRMLoaded] = useState(false);
  const [loadingProgress, setLoadingProgress] = useState(0);
  const [isLoading, setIsLoading] = useState(false);
  const [showSkipButton, setShowSkipButton] = useState(false);
  const [showAvatarModal, setShowAvatarModal] = useState(false);
  const [isLoadingAvatar, setIsLoadingAvatar] = useState(false);
  const [selectedAvatar, setSelectedAvatar] = useState(
    "/models/HatsuneMikuNT.vrm"
  );
  const [showAnimationModal, setShowAnimationModal] = useState(false);
  const [isLoadingAnimation, setIsLoadingAnimation] = useState(false);
  const [selectedAnimation, setSelectedAnimation] = useState(
    "/models/animations/Breathing_Idle.fbx"
  );
  const [enableSmoothCamera, setEnableSmoothCamera] = useState(true);
  const [resetCameraPosition, setResetCameraPosition] = useState(false);
  const [cameraFollowCharacter, setCameraFollowCharacter] = useState(false);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const vrmViewerRef = useRef<VRMViewerRef>(null);
  const blinkIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const fileInputRef = useRef<HTMLInputElement | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const isAudioSetupRef = useRef(false);
  const skipTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  const loadCancelledRef = useRef(false);
  const audioPermissionRequestedRef = useRef(false);

  const handleSkipLoading = () => {
    console.log("‚è≠Ô∏è User skipped loading");
    loadCancelledRef.current = true;
    setIsLoading(false);
    setShowSkipButton(false);
    if (skipTimeoutRef.current) {
      clearTimeout(skipTimeoutRef.current);
      skipTimeoutRef.current = null;
    }
  };

  const startRecording = async () => {
    try {
      // Request audio permission on first use
      if (!audioPermissionRequestedRef.current) {
        console.log("üé§ Requesting microphone permission...");
        audioPermissionRequestedRef.current = true;
      }

      const audioConstraints = selectedInputId
        ? { deviceId: { exact: selectedInputId } }
        : true;

      const stream = await navigator.mediaDevices.getUserMedia({
        audio: audioConstraints,
      });
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        const recordedAudioBlob = new Blob(audioChunksRef.current, {
          type: "audio/webm",
        });

        try {
          // Step 1: Send audio to Whisper for transcription
          const formData = new FormData();
          formData.append("audio", recordedAudioBlob, "recording.webm");

          console.log("üé§ Sending audio to Whisper for transcription...");
          const whisperResponse = await fetch(
            "http://localhost:5001/transcribe",
            {
              method: "POST",
              body: formData,
            }
          );

          if (!whisperResponse.ok) {
            throw new Error("Whisper transcription failed");
          }

          const whisperData = await whisperResponse.json();
          const transcribedText = whisperData.text;
          console.log("‚úÖ Transcription:", transcribedText);

          // Step 2: Query RAG system for relevant context
          console.log("üîç Querying RAG system for context...");
          let ragContext = "";
          try {
            const ragResponse = await fetch("http://localhost:5003/query", {
              method: "POST",
              headers: {
                "Content-Type": "application/json",
              },
              body: JSON.stringify({ query: transcribedText }),
            });

            if (ragResponse.ok) {
              const ragData = await ragResponse.json();
              if (ragData.has_context) {
                ragContext = ragData.context;
                console.log(
                  "‚úÖ RAG Context retrieved:",
                  ragData.contexts.length,
                  "chunks"
                );
              } else {
                console.log("‚Ñπ No relevant context found in documents");
              }
            } else {
              console.warn(
                "‚ö† RAG server unavailable, continuing without context"
              );
            }
          } catch (error) {
            console.warn("‚ö† RAG query failed:", error);
            console.log("  Continuing without document context...");
          }

          // Step 3: Send transcribed text to LLM (mistral:7b) with RAG context
          console.log("ü§ñ Sending to LLM for processing...");

          // Build system prompt with context if available
          let systemPrompt =
            "Kamu adalah asisten AI yang membantu. Selalu jawab dalam Bahasa Indonesia yang sopan dan jelas. Berikan jawaban yang SINGKAT dan LANGSUNG KE INTI. Jangan memberikan penjelasan panjang kecuali diminta. Untuk pertanyaan sederhana, jawab dengan 1-2 kalimat saja.";

          if (ragContext) {
            systemPrompt += `\n\nGunakan informasi berikut sebagai referensi untuk menjawab pertanyaan:\n\n${ragContext}\n\nJawab berdasarkan informasi di atas jika relevan dengan pertanyaan. Jika informasi tidak cukup atau tidak relevan, jawab berdasarkan pengetahuan umum.`;
          }

          const stream = await ollama.chat({
            model: "mistral:7b",
            messages: [
              {
                role: "system",
                content: systemPrompt,
              },
              {
                role: "user",
                content: transcribedText,
              },
            ],
            stream: true,
          });

          let fullResponse = "";
          for await (const part of stream) {
            if (part.message.content) {
              fullResponse += part.message.content;
            }
          }
          console.log("‚úÖ LLM Response:", fullResponse);

          // Step 4: Send LLM response to TTS server
          console.log("üîä Sending to TTS for speech synthesis...");
          const ttsResponse = await fetch("http://localhost:5002/synthesize", {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
            },
            body: JSON.stringify({ text: fullResponse }),
          });

          if (!ttsResponse.ok) {
            throw new Error("TTS synthesis failed");
          }

          const ttsAudioBlob = await ttsResponse.blob();
          const audioUrl = URL.createObjectURL(ttsAudioBlob);
          console.log("‚úÖ TTS audio generated");

          // Step 5: Play TTS audio and animate mouth
          if (audioRef.current) {
            audioRef.current.src = audioUrl;

            // Setup audio analysis for mouth animation (only once)
            if (!isAudioSetupRef.current && audioRef.current) {
              const audioContext = new AudioContext();
              const audioElement = audioRef.current;
              const source =
                audioContext.createMediaElementSource(audioElement);
              const analyser = audioContext.createAnalyser();
              analyser.fftSize = 256;
              source.connect(analyser);
              analyser.connect(audioContext.destination);

              audioContextRef.current = audioContext;
              analyserRef.current = analyser;
              isAudioSetupRef.current = true;
            }

            // Animate mouth based on TTS audio
            if (analyserRef.current) {
              const dataArray = new Uint8Array(
                analyserRef.current.frequencyBinCount
              );
              let isPlaying = true;

              const animateMouth = () => {
                if (!isPlaying || !analyserRef.current) return;

                analyserRef.current.getByteFrequencyData(dataArray);
                const sum = dataArray.reduce((a, b) => a + b, 0);
                const average = sum / dataArray.length;
                const mouthValue = Math.min(Math.max((average - 5) / 50, 0), 1);

                if (vrmViewerRef.current) {
                  vrmViewerRef.current.setExpression("aa", mouthValue);
                }

                requestAnimationFrame(animateMouth);
              };

              // Start animation when audio plays
              audioRef.current.onplay = () => {
                isPlaying = true;
                animateMouth();
              };

              // Stop animation when audio ends
              audioRef.current.onended = () => {
                isPlaying = false;
                if (vrmViewerRef.current) {
                  vrmViewerRef.current.setExpression("aa", 0);
                }
              };
            }

            audioRef.current.play();
          }
        } catch (error) {
          console.error("‚ùå Error in voice processing pipeline:", error);
          alert(
            "Failed to process voice. Please check if all servers are running."
          );
        }

        // Stop all tracks
        stream.getTracks().forEach((track) => track.stop());
      };

      mediaRecorder.start();
      setIsRecording(true);
    } catch (error) {
      console.error("Error accessing microphone:", error);
      alert("Could not access microphone. Please check permissions.");
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
    }
  };

  const handleToggleRecording = () => {
    if (isRecording) {
      stopRecording();
    } else {
      startRecording();
    }
  };

  const handleUploadModel = () => {
    // Don't clear automatically - user should use "Clear 3D Model" first if needed
    fileInputRef.current?.click();
  };

  const handleAvatarSelect = async (avatarPath: string) => {
    try {
      console.log("üîÑ Switching to avatar:", avatarPath);

      // Show loading state in modal
      setIsLoadingAvatar(true);

      // Clear existing model first
      if (vrmViewerRef.current) {
        vrmViewerRef.current.clearScene();
        setIsVRMLoaded(false);
      }

      await new Promise((resolve) => setTimeout(resolve, 150));

      setIsLoading(true);
      setLoadingProgress(0);

      if (vrmViewerRef.current) {
        await vrmViewerRef.current.loadVRM(avatarPath, (progress) => {
          setLoadingProgress(progress);
        });
        setIsLoading(false);
        setIsVRMLoaded(true);
        setSelectedAvatar(avatarPath);
        setIsLoadingAvatar(false);
        setShowAvatarModal(false);
        console.log("‚úÖ Avatar switched successfully!");
      }
    } catch (error) {
      console.error("‚ùå Failed to switch avatar:", error);
      setIsLoading(false);
      setIsVRMLoaded(false);
      setIsLoadingAvatar(false);
    }
  };

  const handleAnimationSelect = async (animationPath: string) => {
    try {
      console.log("üé≠ Loading animation:", animationPath);

      // Show loading state in modal
      setIsLoadingAnimation(true);

      if (vrmViewerRef.current) {
        await vrmViewerRef.current.loadAnimation(animationPath);
      }

      setSelectedAnimation(animationPath);
      setIsLoadingAnimation(false);
      setShowAnimationModal(false);
      console.log("‚úÖ Animation loaded successfully!");
    } catch (error) {
      console.error("‚ùå Failed to load animation:", error);
      setIsLoadingAnimation(false);
    }
  };

  const handleFileSelected = async (
    event: React.ChangeEvent<HTMLInputElement>
  ) => {
    const file = event.target.files?.[0];
    if (file && file.name.endsWith(".vrm")) {
      try {
        console.log(
          "üìÅ File selected:",
          file.name,
          `(${(file.size / 1024 / 1024).toFixed(2)} MB)`
        );

        // Step 1: Clear existing model first
        console.log("üßπ Clearing existing model...");
        if (vrmViewerRef.current) {
          vrmViewerRef.current.clearScene();
          setIsVRMLoaded(false);
        }

        // Step 2: Small delay to ensure cleanup is complete
        await new Promise((resolve) => setTimeout(resolve, 150));

        // Step 3: Read file as ArrayBuffer
        console.log("üìñ Reading file...");
        setIsLoading(true);
        setLoadingProgress(0);

        const arrayBuffer = await file.arrayBuffer();
        console.log("‚úÖ File read complete, loading VRM...");

        // Step 4: Load the new model
        if (vrmViewerRef.current) {
          await vrmViewerRef.current.loadVRM(arrayBuffer, (progress) => {
            setLoadingProgress(progress);
          });
          setIsLoading(false);
          setIsVRMLoaded(true);
          console.log("‚úÖ VRM model loaded successfully!");
          // Reset file input after successful upload
          event.target.value = "";
        }
      } catch (error) {
        console.error("‚ùå Failed to load VRM file:", error);
        alert(
          "Failed to load VRM file. Please make sure it's a valid VRM model."
        );
        // Reset states on error
        setIsLoading(false);
        setIsVRMLoaded(false);
      }
    } else {
      alert("Please select a valid VRM file (.vrm extension)");
    }
  };

  // Audio permission will be requested on first record button press

  // Enumerate audio devices
  useEffect(() => {
    const enumerateDevices = async () => {
      try {
        const devices = await navigator.mediaDevices.enumerateDevices();
        const inputs = devices.filter((device) => device.kind === "audioinput");

        setAudioInputs(inputs);

        if (inputs.length > 0 && !selectedInputId) {
          setSelectedInputId(inputs[0].deviceId);
        }
      } catch (error) {
        console.error("Error enumerating devices:", error);
      }
    };

    enumerateDevices();

    navigator.mediaDevices.addEventListener("devicechange", enumerateDevices);
    return () => {
      navigator.mediaDevices.removeEventListener(
        "devicechange",
        enumerateDevices
      );
    };
  }, [selectedInputId]);

  // Initial load: show loading overlay and progress for default model
  useEffect(() => {
    let cancelled = false;
    const loadDefaultModel = async () => {
      if (vrmViewerRef.current) {
        setIsLoading(true);
        setLoadingProgress(0);
        setShowSkipButton(false);
        loadCancelledRef.current = false;

        // Start timer to show skip button after 10 seconds
        skipTimeoutRef.current = setTimeout(() => {
          if (!cancelled && !loadCancelledRef.current) {
            setShowSkipButton(true);
          }
        }, 10000);

        try {
          await vrmViewerRef.current.loadVRM(selectedAvatar, (progress) => {
            if (!cancelled && !loadCancelledRef.current) {
              setLoadingProgress(progress);
            }
          });
          if (!cancelled && !loadCancelledRef.current) {
            setIsLoading(false);
            setIsVRMLoaded(true);
            setShowSkipButton(false);
            if (skipTimeoutRef.current) {
              clearTimeout(skipTimeoutRef.current);
            }
          }
        } catch {
          if (!cancelled && !loadCancelledRef.current) {
            setIsLoading(false);
            setIsVRMLoaded(false);
            setShowSkipButton(false);
          }
        }
      }
    };
    loadDefaultModel();
    return () => {
      cancelled = true;
      if (skipTimeoutRef.current) {
        clearTimeout(skipTimeoutRef.current);
      }
    };
  }, [selectedAvatar]);

  // Periodic blink idle animation
  useEffect(() => {
    // Don't start blinking until VRM is loaded
    if (!isVRMLoaded) return;

    const triggerBlink = () => {
      if (!vrmViewerRef.current) return;

      // Smooth blink animation with transitions
      const transitionDuration = 100; // 0.1 seconds
      const steps = 10;
      const stepDelay = transitionDuration / steps;

      // Close eyes (0 -> 1)
      let currentStep = 0;
      const closeInterval = setInterval(() => {
        currentStep++;
        const value = currentStep / steps;
        if (vrmViewerRef.current) {
          vrmViewerRef.current.setExpression("blink", value);
        }
        if (currentStep >= steps) {
          clearInterval(closeInterval);

          // Keep eyes closed briefly
          setTimeout(() => {
            // Open eyes (1 -> 0)
            let openStep = steps;
            const openInterval = setInterval(() => {
              openStep--;
              const value = openStep / steps;
              if (vrmViewerRef.current) {
                vrmViewerRef.current.setExpression("blink", value);
              }
              if (openStep <= 0) {
                clearInterval(openInterval);
              }
            }, stepDelay);
          }, 50);
        }
      }, stepDelay);
    };

    // Random blink interval between 2-4 seconds
    const scheduleNextBlink = () => {
      const delay = 2000 + Math.random() * 2000; // 2000-4000ms
      blinkIntervalRef.current = setTimeout(() => {
        triggerBlink();
        scheduleNextBlink();
      }, delay);
    };

    scheduleNextBlink();

    return () => {
      if (blinkIntervalRef.current) {
        clearTimeout(blinkIntervalRef.current);
      }
    };
  }, [isVRMLoaded]);

  // Sync camera controls state
  useEffect(() => {
    if (vrmViewerRef.current) {
      vrmViewerRef.current.setCameraControlsEnabled(enableSmoothCamera);
    }
  }, [enableSmoothCamera]);

  // Sync reset camera position state
  useEffect(() => {
    if (vrmViewerRef.current) {
      vrmViewerRef.current.setResetCameraPosition(resetCameraPosition);
    }
  }, [resetCameraPosition]);

  // Sync camera follow character state
  useEffect(() => {
    if (vrmViewerRef.current) {
      vrmViewerRef.current.setCameraFollowCharacter(cameraFollowCharacter);
    }
  }, [cameraFollowCharacter]);

  return (
    <div className="flex flex-col flex-1 h-screen relative overflow-hidden">
      {/* Loading Overlay */}
      {isLoading && (
        <div className="absolute inset-0 bg-black/50 backdrop-blur-sm z-50 flex items-center justify-center">
          <div className="text-center space-y-4">
            <div className="text-6xl font-bold text-white">
              {loadingProgress}%
            </div>
            <div className="text-xl text-white/80">Loading 3D Model...</div>
            <div className="w-64 h-2 bg-white/20 rounded-full overflow-hidden">
              <div
                className="h-full bg-primary transition-all duration-300"
                style={{ width: `${loadingProgress}%` }}
              />
            </div>
            {showSkipButton && (
              <Button
                onClick={handleSkipLoading}
                variant="outline"
                className="mt-4 bg-white/10 hover:bg-white/20 text-white border-white/30"
              >
                Skip...
              </Button>
            )}
          </div>
        </div>
      )}

      <header className="absolute top-0 left-0 right-0 flex items-center justify-between px-4 h-16 border-b bg-background/80 backdrop-blur-sm z-10">
        <h1 className="text-xl font-bold">3D Avatar Viewer</h1>

        {/* Settings Dropdown */}
        <DropdownMenu>
          <DropdownMenuTrigger asChild>
            <Button
              variant="outline"
              size="sm"
              className="text-base font-semibold"
            >
              Settings
              <SettingsIcon className="ml-2 h-4 w-4" />
            </Button>
          </DropdownMenuTrigger>
          <DropdownMenuContent align="end" className="w-56">
            {/* Smooth Camera Toggle */}
            <div className="flex items-center justify-between px-2 py-3 cursor-pointer hover:bg-accent rounded-sm">
              <span className="text-sm font-medium">Smooth Camera</span>
              <Switch
                checked={enableSmoothCamera}
                onCheckedChange={setEnableSmoothCamera}
              />
            </div>
            {/* Reset Camera Position Toggle */}
            <div className="flex items-center justify-between px-2 py-3 cursor-pointer hover:bg-accent rounded-sm">
              <span className="text-sm font-medium">Reset Camera Position</span>
              <Switch
                checked={resetCameraPosition}
                onCheckedChange={setResetCameraPosition}
              />
            </div>
            {/* Camera Follow Character Toggle */}
            <div className="flex items-center justify-between px-2 py-3 cursor-pointer hover:bg-accent rounded-sm">
              <span className="text-sm font-medium">
                Camera Follow Character
              </span>
              <Switch
                checked={cameraFollowCharacter}
                onCheckedChange={setCameraFollowCharacter}
              />
            </div>
            {/* Upload 3D Model */}
            <DropdownMenuRadioItem
              value="upload"
              onClick={(e) => {
                e.preventDefault();
                handleUploadModel();
              }}
              className="flex flex-col items-center justify-center py-6 cursor-pointer hover:bg-accent"
            >
              <Upload className="h-8 w-8 mb-2" />
              <span className="text-sm font-medium">Upload 3D Model (VRM)</span>
            </DropdownMenuRadioItem>
          </DropdownMenuContent>
        </DropdownMenu>
      </header>
      <main className="flex-1 w-full overflow-hidden">
        <VRMViewer ref={vrmViewerRef} />
      </main>
      <footer className="absolute bottom-0 left-0 right-0 z-10 flex justify-center items-end pb-4">
        {/* Dock with Action Buttons */}
        <Dock magnification={100} distance={140}>
          {/* Home Button */}
          <DockItem>
            <DockLabel>Home</DockLabel>
            <DockIcon>
              <button
                onClick={() => navigate("/")}
                className="h-full w-full flex items-center justify-center"
              >
                <Home className="h-full w-full text-foreground" />
              </button>
            </DockIcon>
          </DockItem>

          {/* Record Button with Microphone Selector */}
          <DockItem className={isRecording ? "animate-pulse" : ""}>
            <DockLabel>{isRecording ? "Stop" : "Record"}</DockLabel>
            <DockIcon>
              <div className="h-full w-full flex items-center justify-center relative">
                <button
                  onClick={handleToggleRecording}
                  className="h-full w-full flex items-center justify-center"
                >
                  <Mic
                    className={`h-full w-full ${
                      isRecording ? "text-red-500" : "text-foreground"
                    }`}
                  />
                </button>
                {/* Microphone Selector Dropdown */}
                <DropdownMenu>
                  <DropdownMenuTrigger asChild>
                    <button className="absolute right-0 top-1/2 -translate-y-1/2 translate-x-[calc(50%+8px)] flex items-center justify-center hover:opacity-70">
                      <ChevronDown className="h-4 w-4 text-foreground" />
                    </button>
                  </DropdownMenuTrigger>
                  <DropdownMenuContent align="start">
                    {audioInputs.map((device) => (
                      <DropdownMenuRadioItem
                        key={device.deviceId}
                        value={device.deviceId}
                        onClick={() => setSelectedInputId(device.deviceId)}
                      >
                        {device.label ||
                          `Microphone (${device.deviceId.slice(0, 5)})`}
                      </DropdownMenuRadioItem>
                    ))}
                  </DropdownMenuContent>
                </DropdownMenu>
              </div>
            </DockIcon>
          </DockItem>

          {/* Animation Button */}
          <DockItem>
            <DockLabel>Animation</DockLabel>
            <DockIcon>
              <button
                onClick={() => setShowAnimationModal(true)}
                className="h-full w-full flex items-center justify-center"
              >
                <svg
                  viewBox="0 0 36 36"
                  className="h-full w-full text-foreground"
                  fill="none"
                >
                  <use href="/src/assets/sprite.svg#animation" />
                </svg>
              </button>
            </DockIcon>
          </DockItem>

          {/* 3D Model Button */}
          <DockItem>
            <DockLabel>3D Avatar</DockLabel>
            <DockIcon>
              <button
                onClick={() => setShowAvatarModal(true)}
                className="h-full w-full flex items-center justify-center"
              >
                <svg
                  viewBox="0 0 24 24"
                  className="h-full w-full text-foreground"
                  fill="none"
                >
                  <use href="/src/assets/sprite.svg#3D" />
                </svg>
              </button>
            </DockIcon>
          </DockItem>
        </Dock>
      </footer>

      {/* 3D Avatar Selection Modal */}
      <Dialog open={showAvatarModal} onOpenChange={setShowAvatarModal}>
        <DialogContent className="sm:max-w-[600px]">
          <DialogHeader>
            <DialogTitle>Select 3D Avatar</DialogTitle>
          </DialogHeader>
          {isLoadingAvatar && (
            <div className="absolute inset-0 bg-black/50 backdrop-blur-sm z-50 flex items-center justify-center rounded-lg">
              <div className="text-center space-y-4">
                <div className="text-2xl font-bold text-white">Loading...</div>
              </div>
            </div>
          )}
          <div className="max-h-[60vh] overflow-y-auto">
            <div className="grid grid-cols-3 gap-4 p-4">
              {predefinedAvatars.map((avatar) => (
                <button
                  key={avatar.path}
                  onClick={() => handleAvatarSelect(avatar.path)}
                  className="group relative flex flex-col items-center gap-2 transition-transform hover:-translate-y-2"
                >
                  <div
                    className={`w-full aspect-square rounded-2xl overflow-hidden border-2 transition-colors ${
                      selectedAvatar === avatar.path
                        ? "border-primary"
                        : "border-transparent group-hover:border-primary/50"
                    }`}
                  >
                    <img
                      src={avatar.thumbnail}
                      alt={avatar.name}
                      className="w-full h-full object-cover"
                    />
                  </div>
                  <span className="text-sm font-medium text-center">
                    {avatar.name}
                  </span>
                </button>
              ))}
            </div>
          </div>
        </DialogContent>
      </Dialog>

      {/* Animation Selection Modal */}
      <Dialog open={showAnimationModal} onOpenChange={setShowAnimationModal}>
        <DialogContent className="sm:max-w-[600px]">
          <DialogHeader>
            <DialogTitle>Select Animation</DialogTitle>
          </DialogHeader>
          {isLoadingAnimation && (
            <div className="absolute inset-0 bg-black/50 backdrop-blur-sm z-50 flex items-center justify-center rounded-lg">
              <div className="text-center space-y-4">
                <div className="text-2xl font-bold text-white">Loading...</div>
              </div>
            </div>
          )}
          <div className="max-h-[60vh] overflow-y-auto">
            <div className="grid grid-cols-3 gap-4 p-4">
              {predefinedAnimations.map((animation) => (
                <button
                  key={animation.path}
                  onClick={() => handleAnimationSelect(animation.path)}
                  className="group relative flex flex-col items-center gap-2 transition-transform hover:-translate-y-2"
                >
                  <div
                    className={`w-full aspect-square rounded-2xl overflow-hidden border-2 transition-colors ${
                      selectedAnimation === animation.path
                        ? "border-primary"
                        : "border-transparent group-hover:border-primary/50"
                    }`}
                  >
                    <img
                      src={animation.thumbnail}
                      alt={animation.name}
                      className="w-full h-full object-cover"
                    />
                  </div>
                  <span className="text-sm font-medium text-center">
                    {animation.name}
                  </span>
                </button>
              ))}
            </div>
          </div>
        </DialogContent>
      </Dialog>

      <audio ref={audioRef} className="hidden" />
      <input
        ref={fileInputRef}
        type="file"
        accept=".vrm"
        onChange={handleFileSelected}
        className="hidden"
      />
    </div>
  );
};

export default AvatarPage;
